{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g0J3r6m3-PO0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading (수술 시 사망 데이터)\n",
        "data=pd.read_csv(\"https://raw.githubusercontent.com/GonieAhn/Data-Science-online-course-from-gonie/main/Data%20Store/example_data.csv\")"
      ],
      "metadata": {
        "id": "RgjTQcNpH5Dw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "0KpKLCFkH76t",
        "outputId": "78664109-eaa9-4bb7-e475-6b8f308f0d80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           censor        event         age        wtkg        hemo  \\\n",
              "count  532.000000   532.000000  532.000000  532.000000  532.000000   \n",
              "mean     0.340226   801.236842   35.225564   76.061855    0.078947   \n",
              "std      0.474231   326.887929    8.852094   13.224698    0.269910   \n",
              "min      0.000000    33.000000   13.000000   47.401000    0.000000   \n",
              "25%      0.000000   535.750000   29.000000   67.500000    0.000000   \n",
              "50%      0.000000   933.500000   34.000000   74.600000    0.000000   \n",
              "75%      1.000000  1081.000000   40.000000   83.502000    0.000000   \n",
              "max      1.000000  1231.000000   70.000000  149.000000    1.000000   \n",
              "\n",
              "             homo       drugs      karnof      oprior         z30  ...  \\\n",
              "count  532.000000  532.000000  532.000000  532.000000  532.000000  ...   \n",
              "mean     0.640977    0.118421   95.432331    0.030075    0.546992  ...   \n",
              "std      0.480165    0.323410    5.981856    0.170955    0.498255  ...   \n",
              "min      0.000000    0.000000   70.000000    0.000000    0.000000  ...   \n",
              "25%      0.000000    0.000000   90.000000    0.000000    0.000000  ...   \n",
              "50%      1.000000    0.000000  100.000000    0.000000    1.000000  ...   \n",
              "75%      1.000000    0.000000  100.000000    0.000000    1.000000  ...   \n",
              "max      1.000000    1.000000  100.000000    1.000000    1.000000  ...   \n",
              "\n",
              "           gender        str2       strat     symptom        cd40       cd420  \\\n",
              "count  532.000000  532.000000  532.000000  532.000000  532.000000  532.000000   \n",
              "mean     0.812030    0.580827    1.981203    0.167293  353.204887  336.139098   \n",
              "std      0.391056    0.493888    0.905946    0.373589  114.105253  130.961573   \n",
              "min      0.000000    0.000000    1.000000    0.000000  103.000000   49.000000   \n",
              "25%      1.000000    0.000000    1.000000    0.000000  271.000000  243.750000   \n",
              "50%      1.000000    1.000000    2.000000    0.000000  346.000000  330.500000   \n",
              "75%      1.000000    1.000000    3.000000    0.000000  422.000000  418.000000   \n",
              "max      1.000000    1.000000    3.000000    1.000000  771.000000  909.000000   \n",
              "\n",
              "            cd496           r         cd80        cd820  \n",
              "count  532.000000  532.000000   532.000000   532.000000  \n",
              "mean   173.146617    0.603383   987.250000   928.214286  \n",
              "std    191.455406    0.489656   475.223907   438.569798  \n",
              "min     -1.000000    0.000000   221.000000   150.000000  \n",
              "25%     -1.000000    0.000000   653.250000   626.500000  \n",
              "50%    113.000000    1.000000   881.000000   818.000000  \n",
              "75%    324.000000    1.000000  1190.000000  1164.000000  \n",
              "max    857.000000    1.000000  4255.000000  3130.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d543e89-668a-4a09-bb22-08f93c4ecb18\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>censor</th>\n",
              "      <th>event</th>\n",
              "      <th>age</th>\n",
              "      <th>wtkg</th>\n",
              "      <th>hemo</th>\n",
              "      <th>homo</th>\n",
              "      <th>drugs</th>\n",
              "      <th>karnof</th>\n",
              "      <th>oprior</th>\n",
              "      <th>z30</th>\n",
              "      <th>...</th>\n",
              "      <th>gender</th>\n",
              "      <th>str2</th>\n",
              "      <th>strat</th>\n",
              "      <th>symptom</th>\n",
              "      <th>cd40</th>\n",
              "      <th>cd420</th>\n",
              "      <th>cd496</th>\n",
              "      <th>r</th>\n",
              "      <th>cd80</th>\n",
              "      <th>cd820</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>532.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.340226</td>\n",
              "      <td>801.236842</td>\n",
              "      <td>35.225564</td>\n",
              "      <td>76.061855</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.640977</td>\n",
              "      <td>0.118421</td>\n",
              "      <td>95.432331</td>\n",
              "      <td>0.030075</td>\n",
              "      <td>0.546992</td>\n",
              "      <td>...</td>\n",
              "      <td>0.812030</td>\n",
              "      <td>0.580827</td>\n",
              "      <td>1.981203</td>\n",
              "      <td>0.167293</td>\n",
              "      <td>353.204887</td>\n",
              "      <td>336.139098</td>\n",
              "      <td>173.146617</td>\n",
              "      <td>0.603383</td>\n",
              "      <td>987.250000</td>\n",
              "      <td>928.214286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.474231</td>\n",
              "      <td>326.887929</td>\n",
              "      <td>8.852094</td>\n",
              "      <td>13.224698</td>\n",
              "      <td>0.269910</td>\n",
              "      <td>0.480165</td>\n",
              "      <td>0.323410</td>\n",
              "      <td>5.981856</td>\n",
              "      <td>0.170955</td>\n",
              "      <td>0.498255</td>\n",
              "      <td>...</td>\n",
              "      <td>0.391056</td>\n",
              "      <td>0.493888</td>\n",
              "      <td>0.905946</td>\n",
              "      <td>0.373589</td>\n",
              "      <td>114.105253</td>\n",
              "      <td>130.961573</td>\n",
              "      <td>191.455406</td>\n",
              "      <td>0.489656</td>\n",
              "      <td>475.223907</td>\n",
              "      <td>438.569798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>47.401000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>221.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>535.750000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>67.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>271.000000</td>\n",
              "      <td>243.750000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>653.250000</td>\n",
              "      <td>626.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>933.500000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>74.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>330.500000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>881.000000</td>\n",
              "      <td>818.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1081.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>83.502000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>422.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>324.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1190.000000</td>\n",
              "      <td>1164.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1231.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>771.000000</td>\n",
              "      <td>909.000000</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4255.000000</td>\n",
              "      <td>3130.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d543e89-668a-4a09-bb22-08f93c4ecb18')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d543e89-668a-4a09-bb22-08f93c4ecb18 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d543e89-668a-4a09-bb22-08f93c4ecb18');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f0c78174-a648-4c1f-8122-2cdfb68ee019\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0c78174-a648-4c1f-8122-2cdfb68ee019')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f0c78174-a648-4c1f-8122-2cdfb68ee019 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X's & Y Split\n",
        "Y = data['censor']\n",
        "X = data.drop(columns=['censor'])"
      ],
      "metadata": {
        "id": "qLl87FJFID_J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = list(range(X.shape[0]))\n",
        "train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2021)\n",
        "print(f\"# of Train data : {len(train_idx)}\")\n",
        "print(f\"# of valid data : {len(valid_idx)}\")\n",
        "print(f\"# of Train data Y : {Counter(Y.iloc[train_idx])}\")\n",
        "print(f\"# of valid data Y : {Counter(Y.iloc[valid_idx])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op8jQF1wIGO6",
        "outputId": "c4e8ba2b-fb2f-4e2c-8c9b-2908079738ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of Train data : 372\n",
            "# of valid data : 160\n",
            "# of Train data Y : Counter({0: 241, 1: 131})\n",
            "# of valid data Y : Counter({0: 110, 1: 50})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Machine Parameters\n",
        "  - Package : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "  - n_estimators : # of Tree\n",
        "  - learning_rate : learning_rate과 n_estimator와 Trade-off 관계가 있음\n",
        "    - Weight applied to each classifier at each boosting iteration\n",
        "  - max_features : Feature 수 sampling (Overfitting 방지)\n",
        "  - subsample : Data Subsample (Overfitting 방지, Bootstrap X)\n",
        "  - max_depth : Tree의 최대 깊이 제한"
      ],
      "metadata": {
        "id": "kLXwwRdKIVse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GBM Hyperparameter\n",
        "estimators = [10, 20, 50]\n",
        "learning = [0.05, 0.1, 0.5]\n",
        "subsam = [0.5, 0.75, 1]\n",
        "\n",
        "# Modeling\n",
        "save_est = []\n",
        "save_lr = []\n",
        "save_sub = []\n",
        "f1_score_ = []\n",
        "\n",
        "cnt = 0\n",
        "for est in estimators:\n",
        "    for lr in learning:\n",
        "        for sub in subsam:\n",
        "            print(f\">>> {cnt} <<<\")\n",
        "            cnt += 1\n",
        "            print(f\"Number of Estimators : {est}, Learning Rate : {lr}, Subsample : {sub}\")\n",
        "\n",
        "            model = GradientBoostingClassifier(n_estimators=est,\n",
        "                                               learning_rate=lr,\n",
        "                                               subsample=sub,\n",
        "                                               random_state=119)\n",
        "            model.fit(X.iloc[train_idx], Y.iloc[train_idx])\n",
        "\n",
        "            # Train Acc\n",
        "            y_pre_train = model.predict(X.iloc[train_idx])\n",
        "            cm_train = confusion_matrix(Y.iloc[train_idx], y_pre_train)\n",
        "            print(\"Train Confusion Matrix\")\n",
        "            print(cm_train)\n",
        "            print(f\"Train Acc : {(cm_train[0,0] + cm_train[1,1])/cm_train.sum()}\")\n",
        "            print(f\"Train F1-Score : {f1_score(Y.iloc[train_idx], y_pre_train)}\")\n",
        "\n",
        "            # Test Acc\n",
        "            y_pre_test = model.predict(X.iloc[valid_idx])\n",
        "            cm_test = confusion_matrix(Y.iloc[valid_idx], y_pre_test)\n",
        "            print(\"Test Confusion Matrix\")\n",
        "            print(cm_test)\n",
        "            print(f\"TesT Acc : {(cm_test[0,0] + cm_test[1,1])/cm_test.sum()}\")\n",
        "            print(f\"Test F1-Score : {f1_score(Y.iloc[valid_idx], y_pre_test)}\")\n",
        "            print(\"-----------------------------------------------------------------------\")\n",
        "            print(\"-----------------------------------------------------------------------\")\n",
        "            save_est.append(est)\n",
        "            save_lr.append(lr)\n",
        "            save_sub.append(sub)\n",
        "            f1_score_.append(f1_score(Y.iloc[valid_idx], y_pre_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3_KitjxIUKu",
        "outputId": "e46388f0-2b69-4ef3-9073-941fb870c95f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> 0 <<<\n",
            "Number of Estimators : 10, Learning Rate : 0.05, Subsample : 0.5\n",
            "Train Confusion Matrix\n",
            "[[240   1]\n",
            " [ 51  80]]\n",
            "Train Acc : 0.8602150537634409\n",
            "Train F1-Score : 0.7547169811320754\n",
            "Test Confusion Matrix\n",
            "[[102   8]\n",
            " [ 12  38]]\n",
            "TesT Acc : 0.875\n",
            "Test F1-Score : 0.7916666666666667\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 1 <<<\n",
            "Number of Estimators : 10, Learning Rate : 0.05, Subsample : 0.75\n",
            "Train Confusion Matrix\n",
            "[[240   1]\n",
            " [ 53  78]]\n",
            "Train Acc : 0.8548387096774194\n",
            "Train F1-Score : 0.7428571428571428\n",
            "Test Confusion Matrix\n",
            "[[105   5]\n",
            " [ 13  37]]\n",
            "TesT Acc : 0.8875\n",
            "Test F1-Score : 0.8043478260869565\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 2 <<<\n",
            "Number of Estimators : 10, Learning Rate : 0.05, Subsample : 1\n",
            "Train Confusion Matrix\n",
            "[[237   4]\n",
            " [ 40  91]]\n",
            "Train Acc : 0.8817204301075269\n",
            "Train F1-Score : 0.8053097345132744\n",
            "Test Confusion Matrix\n",
            "[[104   6]\n",
            " [ 11  39]]\n",
            "TesT Acc : 0.89375\n",
            "Test F1-Score : 0.8210526315789474\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 3 <<<\n",
            "Number of Estimators : 10, Learning Rate : 0.1, Subsample : 0.5\n",
            "Train Confusion Matrix\n",
            "[[232   9]\n",
            " [ 23 108]]\n",
            "Train Acc : 0.9139784946236559\n",
            "Train F1-Score : 0.870967741935484\n",
            "Test Confusion Matrix\n",
            "[[98 12]\n",
            " [ 4 46]]\n",
            "TesT Acc : 0.9\n",
            "Test F1-Score : 0.851851851851852\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 4 <<<\n",
            "Number of Estimators : 10, Learning Rate : 0.1, Subsample : 0.75\n",
            "Train Confusion Matrix\n",
            "[[230  11]\n",
            " [ 19 112]]\n",
            "Train Acc : 0.9193548387096774\n",
            "Train F1-Score : 0.8818897637795274\n",
            "Test Confusion Matrix\n",
            "[[98 12]\n",
            " [ 3 47]]\n",
            "TesT Acc : 0.90625\n",
            "Test F1-Score : 0.8623853211009174\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 5 <<<\n",
            "Number of Estimators : 10, Learning Rate : 0.1, Subsample : 1\n",
            "Train Confusion Matrix\n",
            "[[236   5]\n",
            " [ 30 101]]\n",
            "Train Acc : 0.9059139784946236\n",
            "Train F1-Score : 0.8523206751054853\n",
            "Test Confusion Matrix\n",
            "[[100  10]\n",
            " [  9  41]]\n",
            "TesT Acc : 0.88125\n",
            "Test F1-Score : 0.8118811881188118\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 6 <<<\n",
            "Number of Estimators : 10, Learning Rate : 0.5, Subsample : 0.5\n",
            "Train Confusion Matrix\n",
            "[[234   7]\n",
            " [  5 126]]\n",
            "Train Acc : 0.967741935483871\n",
            "Train F1-Score : 0.9545454545454546\n",
            "Test Confusion Matrix\n",
            "[[89 21]\n",
            " [ 5 45]]\n",
            "TesT Acc : 0.8375\n",
            "Test F1-Score : 0.7758620689655172\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 7 <<<\n",
            "Number of Estimators : 10, Learning Rate : 0.5, Subsample : 0.75\n",
            "Train Confusion Matrix\n",
            "[[234   7]\n",
            " [  4 127]]\n",
            "Train Acc : 0.9704301075268817\n",
            "Train F1-Score : 0.9584905660377357\n",
            "Test Confusion Matrix\n",
            "[[94 16]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.8875\n",
            "Test F1-Score : 0.8421052631578947\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 8 <<<\n",
            "Number of Estimators : 10, Learning Rate : 0.5, Subsample : 1\n",
            "Train Confusion Matrix\n",
            "[[233   8]\n",
            " [  6 125]]\n",
            "Train Acc : 0.9623655913978495\n",
            "Train F1-Score : 0.9469696969696969\n",
            "Test Confusion Matrix\n",
            "[[91 19]\n",
            " [ 3 47]]\n",
            "TesT Acc : 0.8625\n",
            "Test F1-Score : 0.810344827586207\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 9 <<<\n",
            "Number of Estimators : 20, Learning Rate : 0.05, Subsample : 0.5\n",
            "Train Confusion Matrix\n",
            "[[232   9]\n",
            " [ 18 113]]\n",
            "Train Acc : 0.9274193548387096\n",
            "Train F1-Score : 0.8932806324110673\n",
            "Test Confusion Matrix\n",
            "[[97 13]\n",
            " [ 1 49]]\n",
            "TesT Acc : 0.9125\n",
            "Test F1-Score : 0.8749999999999999\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 10 <<<\n",
            "Number of Estimators : 20, Learning Rate : 0.05, Subsample : 0.75\n",
            "Train Confusion Matrix\n",
            "[[233   8]\n",
            " [ 22 109]]\n",
            "Train Acc : 0.9193548387096774\n",
            "Train F1-Score : 0.8790322580645161\n",
            "Test Confusion Matrix\n",
            "[[99 11]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.91875\n",
            "Test F1-Score : 0.8807339449541285\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 11 <<<\n",
            "Number of Estimators : 20, Learning Rate : 0.05, Subsample : 1\n",
            "Train Confusion Matrix\n",
            "[[237   4]\n",
            " [ 30 101]]\n",
            "Train Acc : 0.9086021505376344\n",
            "Train F1-Score : 0.8559322033898304\n",
            "Test Confusion Matrix\n",
            "[[101   9]\n",
            " [  7  43]]\n",
            "TesT Acc : 0.9\n",
            "Test F1-Score : 0.8431372549019608\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 12 <<<\n",
            "Number of Estimators : 20, Learning Rate : 0.1, Subsample : 0.5\n",
            "Train Confusion Matrix\n",
            "[[229  12]\n",
            " [ 13 118]]\n",
            "Train Acc : 0.9327956989247311\n",
            "Train F1-Score : 0.9042145593869731\n",
            "Test Confusion Matrix\n",
            "[[94 16]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.8875\n",
            "Test F1-Score : 0.8421052631578947\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 13 <<<\n",
            "Number of Estimators : 20, Learning Rate : 0.1, Subsample : 0.75\n",
            "Train Confusion Matrix\n",
            "[[233   8]\n",
            " [ 10 121]]\n",
            "Train Acc : 0.9516129032258065\n",
            "Train F1-Score : 0.9307692307692308\n",
            "Test Confusion Matrix\n",
            "[[92 18]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.875\n",
            "Test F1-Score : 0.8275862068965517\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 14 <<<\n",
            "Number of Estimators : 20, Learning Rate : 0.1, Subsample : 1\n",
            "Train Confusion Matrix\n",
            "[[230  11]\n",
            " [ 12 119]]\n",
            "Train Acc : 0.9381720430107527\n",
            "Train F1-Score : 0.9118773946360154\n",
            "Test Confusion Matrix\n",
            "[[93 17]\n",
            " [ 1 49]]\n",
            "TesT Acc : 0.8875\n",
            "Test F1-Score : 0.8448275862068965\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 15 <<<\n",
            "Number of Estimators : 20, Learning Rate : 0.5, Subsample : 0.5\n",
            "Train Confusion Matrix\n",
            "[[239   2]\n",
            " [  0 131]]\n",
            "Train Acc : 0.9946236559139785\n",
            "Train F1-Score : 0.9924242424242424\n",
            "Test Confusion Matrix\n",
            "[[92 18]\n",
            " [ 8 42]]\n",
            "TesT Acc : 0.8375\n",
            "Test F1-Score : 0.7636363636363636\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 16 <<<\n",
            "Number of Estimators : 20, Learning Rate : 0.5, Subsample : 0.75\n",
            "Train Confusion Matrix\n",
            "[[241   0]\n",
            " [  0 131]]\n",
            "Train Acc : 1.0\n",
            "Train F1-Score : 1.0\n",
            "Test Confusion Matrix\n",
            "[[93 17]\n",
            " [ 3 47]]\n",
            "TesT Acc : 0.875\n",
            "Test F1-Score : 0.8245614035087719\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 17 <<<\n",
            "Number of Estimators : 20, Learning Rate : 0.5, Subsample : 1\n",
            "Train Confusion Matrix\n",
            "[[240   1]\n",
            " [  0 131]]\n",
            "Train Acc : 0.9973118279569892\n",
            "Train F1-Score : 0.9961977186311787\n",
            "Test Confusion Matrix\n",
            "[[89 21]\n",
            " [ 5 45]]\n",
            "TesT Acc : 0.8375\n",
            "Test F1-Score : 0.7758620689655172\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 18 <<<\n",
            "Number of Estimators : 50, Learning Rate : 0.05, Subsample : 0.5\n",
            "Train Confusion Matrix\n",
            "[[231  10]\n",
            " [ 13 118]]\n",
            "Train Acc : 0.9381720430107527\n",
            "Train F1-Score : 0.9111969111969112\n",
            "Test Confusion Matrix\n",
            "[[91 19]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.86875\n",
            "Test F1-Score : 0.8205128205128206\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 19 <<<\n",
            "Number of Estimators : 50, Learning Rate : 0.05, Subsample : 0.75\n",
            "Train Confusion Matrix\n",
            "[[232   9]\n",
            " [ 11 120]]\n",
            "Train Acc : 0.946236559139785\n",
            "Train F1-Score : 0.923076923076923\n",
            "Test Confusion Matrix\n",
            "[[91 19]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.86875\n",
            "Test F1-Score : 0.8205128205128206\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 20 <<<\n",
            "Number of Estimators : 50, Learning Rate : 0.05, Subsample : 1\n",
            "Train Confusion Matrix\n",
            "[[230  11]\n",
            " [  8 123]]\n",
            "Train Acc : 0.9489247311827957\n",
            "Train F1-Score : 0.9283018867924528\n",
            "Test Confusion Matrix\n",
            "[[95 15]\n",
            " [ 1 49]]\n",
            "TesT Acc : 0.9\n",
            "Test F1-Score : 0.8596491228070174\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 21 <<<\n",
            "Number of Estimators : 50, Learning Rate : 0.1, Subsample : 0.5\n",
            "Train Confusion Matrix\n",
            "[[235   6]\n",
            " [  6 125]]\n",
            "Train Acc : 0.967741935483871\n",
            "Train F1-Score : 0.9541984732824428\n",
            "Test Confusion Matrix\n",
            "[[90 20]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.8625\n",
            "Test F1-Score : 0.8135593220338982\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 22 <<<\n",
            "Number of Estimators : 50, Learning Rate : 0.1, Subsample : 0.75\n",
            "Train Confusion Matrix\n",
            "[[238   3]\n",
            " [  5 126]]\n",
            "Train Acc : 0.978494623655914\n",
            "Train F1-Score : 0.9692307692307692\n",
            "Test Confusion Matrix\n",
            "[[91 19]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.86875\n",
            "Test F1-Score : 0.8205128205128206\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 23 <<<\n",
            "Number of Estimators : 50, Learning Rate : 0.1, Subsample : 1\n",
            "Train Confusion Matrix\n",
            "[[235   6]\n",
            " [  2 129]]\n",
            "Train Acc : 0.978494623655914\n",
            "Train F1-Score : 0.9699248120300753\n",
            "Test Confusion Matrix\n",
            "[[91 19]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.86875\n",
            "Test F1-Score : 0.8205128205128206\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 24 <<<\n",
            "Number of Estimators : 50, Learning Rate : 0.5, Subsample : 0.5\n",
            "Train Confusion Matrix\n",
            "[[241   0]\n",
            " [  0 131]]\n",
            "Train Acc : 1.0\n",
            "Train F1-Score : 1.0\n",
            "Test Confusion Matrix\n",
            "[[91 19]\n",
            " [ 5 45]]\n",
            "TesT Acc : 0.85\n",
            "Test F1-Score : 0.7894736842105263\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 25 <<<\n",
            "Number of Estimators : 50, Learning Rate : 0.5, Subsample : 0.75\n",
            "Train Confusion Matrix\n",
            "[[241   0]\n",
            " [  0 131]]\n",
            "Train Acc : 1.0\n",
            "Train F1-Score : 1.0\n",
            "Test Confusion Matrix\n",
            "[[92 18]\n",
            " [ 3 47]]\n",
            "TesT Acc : 0.86875\n",
            "Test F1-Score : 0.8173913043478259\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 26 <<<\n",
            "Number of Estimators : 50, Learning Rate : 0.5, Subsample : 1\n",
            "Train Confusion Matrix\n",
            "[[241   0]\n",
            " [  0 131]]\n",
            "Train Acc : 1.0\n",
            "Train F1-Score : 1.0\n",
            "Test Confusion Matrix\n",
            "[[89 21]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.85625\n",
            "Test F1-Score : 0.8067226890756302\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = GradientBoostingClassifier(n_estimators=save_est[np.argmax(f1_score_)],\n",
        "                                        learning_rate=save_lr[np.argmax(f1_score_)],\n",
        "                                        subsample = save_sub[np.argmax(f1_score_)],\n",
        "                                        random_state=119)\n",
        "best_model.fit(X.iloc[train_idx], Y.iloc[train_idx])\n",
        "\n",
        "# Train Acc\n",
        "y_pre_train = best_model.predict(X.iloc[train_idx])\n",
        "cm_train = confusion_matrix(Y.iloc[train_idx], y_pre_train)\n",
        "print(\"Train Confusion Matrix\")\n",
        "print(cm_train)\n",
        "print(f\"Train Acc : {(cm_train[0,0] + cm_train[1,1])/cm_train.sum()}\")\n",
        "print(f\"Train F1-Score : {f1_score(Y.iloc[train_idx], y_pre_train)}\")\n",
        "\n",
        "# Test Acc\n",
        "y_pre_test = best_model.predict(X.iloc[valid_idx])\n",
        "cm_test = confusion_matrix(Y.iloc[valid_idx], y_pre_test)\n",
        "print(\"Test Confusion Matrix\")\n",
        "print(cm_test)\n",
        "print(f\"TesT Acc : {(cm_test[0,0] + cm_test[1,1])/cm_test.sum()}\")\n",
        "print(f\"Test F1-Score : {f1_score(Y.iloc[valid_idx], y_pre_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWMQ6dPxIxRj",
        "outputId": "bc1776ca-0e5f-4085-a867-164d6694bf23"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Confusion Matrix\n",
            "[[233   8]\n",
            " [ 22 109]]\n",
            "Train Acc : 0.9193548387096774\n",
            "Train F1-Score : 0.8790322580645161\n",
            "Test Confusion Matrix\n",
            "[[99 11]\n",
            " [ 2 48]]\n",
            "TesT Acc : 0.91875\n",
            "Test F1-Score : 0.8807339449541285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map = pd.DataFrame(sorted(zip(best_model.feature_importances_, X.columns), reverse=True), columns=['Score', 'Feature'])\n",
        "print(feature_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov_PYVEBKT97",
        "outputId": "1b7ee3f3-57dd-4ea7-f6c1-2731d2400d70"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Score  Feature\n",
            "0   0.671843    event\n",
            "1   0.064817        r\n",
            "2   0.060131    cd496\n",
            "3   0.046942     wtkg\n",
            "4   0.043351  preanti\n",
            "5   0.033353    cd420\n",
            "6   0.017538     cd80\n",
            "7   0.015869     race\n",
            "8   0.015430      age\n",
            "9   0.012291      z30\n",
            "10  0.008892     cd40\n",
            "11  0.006452   karnof\n",
            "12  0.001652     homo\n",
            "13  0.001437     str2\n",
            "14  0.000000   zprior\n",
            "15  0.000000  symptom\n",
            "16  0.000000    strat\n",
            "17  0.000000   oprior\n",
            "18  0.000000     hemo\n",
            "19  0.000000   gender\n",
            "20  0.000000    drugs\n",
            "21  0.000000    cd820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importance Score Top 10\n",
        "feature_map_20 = feature_map.iloc[:10]\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.barplot(x=\"Score\", y=\"Feature\", data=feature_map_20.sort_values(by=\"Score\", ascending=False), errwidth=40, palette='Pastel1')\n",
        "plt.title('Gradient Boosting Machine Importance Features')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "dsdTzM4OKeBT",
        "outputId": "4d88886c-82c3-42aa-bdb9-d4585a2a28cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "OtkjSYfLKjCN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading (당뇨병)\n",
        "data = pd.read_csv('https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt', sep='\\t')"
      ],
      "metadata": {
        "id": "hYAKL63jKwlb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X's & Y Split\n",
        "Y = data['Y']\n",
        "X = data.drop(columns=['Y'])\n",
        "X = pd.get_dummies(X, columns=['SEX'])\n",
        "idx = list(range(X.shape[0]))\n",
        "train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2023)\n",
        "print(f\"# of Train data : {len(train_idx)}\")\n",
        "print(f\"# of valid data : {len(valid_idx)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpFsWVogKzJE",
        "outputId": "23340624-fbb7-4ff9-bfa6-7f6c1387b047"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of Train data : 309\n",
            "# of valid data : 133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GBM Hyperparameter\n",
        "estimators = [70, 90, 120]\n",
        "learning = [0.05, 0.1, 0.5]\n",
        "subsam = [0.5, 0.75, 1]\n",
        "\n",
        "# Modeling\n",
        "save_est = []\n",
        "save_lr = []\n",
        "save_sub = []\n",
        "\n",
        "cnt = 0\n",
        "for est in estimators:\n",
        "    for lr in learning:\n",
        "        for sub in subsam:\n",
        "            print(\">>> {} <<<\".format(cnt))\n",
        "            cnt += 1\n",
        "            print(f\"Number of Estimators : {est}, Learning Rate : {lr}, Subsample : {sub}\")\n",
        "\n",
        "            model = GradientBoostingRegressor(n_estimators=est,\n",
        "                                               learning_rate=lr,\n",
        "                                               subsample=sub,\n",
        "                                               random_state=119)\n",
        "            model.fit(X.iloc[train_idx], Y.iloc[train_idx])\n",
        "\n",
        "            # Train Acc\n",
        "            y_pre_train = model.predict(X.iloc[train_idx])\n",
        "            rmse_train = np.sqrt(mean_squared_error(Y.iloc[train_idx], y_pre_train))\n",
        "            print(f\"Train RMSE : {np.sqrt(mean_squared_error(Y.iloc[train_idx], y_pre_train))}\")\n",
        "            print(f\"Train R2 : {r2_score(Y.iloc[train_idx], y_pre_train)}\")\n",
        "\n",
        "            # Test Acc\n",
        "            y_pre_test = model.predict(X.iloc[valid_idx])\n",
        "            print(f\"TesT RMSE : {np.sqrt(mean_squared_error(Y.iloc[valid_idx], y_pre_test))}\")\n",
        "            print(f\"Test R2 : {r2_score(Y.iloc[valid_idx], y_pre_test)}\")\n",
        "            print(\"-----------------------------------------------------------------------\")\n",
        "            print(\"-----------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-su2Ka0tK0dS",
        "outputId": "aa963923-8f21-4188-97c3-5b4976c843c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> 0 <<<\n",
            "Number of Estimators : 70, Learning Rate : 0.05, Subsample : 0.5\n",
            "Train RMSE : 39.14524476414566\n",
            "Train R2 : 0.7266482689092394\n",
            "TesT RMSE : 57.075650385405474\n",
            "Test R2 : 0.5038118129452638\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 1 <<<\n",
            "Number of Estimators : 70, Learning Rate : 0.05, Subsample : 0.75\n",
            "Train RMSE : 38.51365298879307\n",
            "Train R2 : 0.7353979352254565\n",
            "TesT RMSE : 58.69109886674094\n",
            "Test R2 : 0.4753264581347395\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 2 <<<\n",
            "Number of Estimators : 70, Learning Rate : 0.05, Subsample : 1\n",
            "Train RMSE : 39.11886805219846\n",
            "Train R2 : 0.7270165226149345\n",
            "TesT RMSE : 59.67155356647381\n",
            "Test R2 : 0.4576503396488516\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 3 <<<\n",
            "Number of Estimators : 70, Learning Rate : 0.1, Subsample : 0.5\n",
            "Train RMSE : 31.3856851151691\n",
            "Train R2 : 0.8242776392350968\n",
            "TesT RMSE : 59.3050012943238\n",
            "Test R2 : 0.46429299909323707\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 4 <<<\n",
            "Number of Estimators : 70, Learning Rate : 0.1, Subsample : 0.75\n",
            "Train RMSE : 30.71540289607168\n",
            "Train R2 : 0.8317030538858089\n",
            "TesT RMSE : 60.57729942938456\n",
            "Test R2 : 0.4410608897917071\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 5 <<<\n",
            "Number of Estimators : 70, Learning Rate : 0.1, Subsample : 1\n",
            "Train RMSE : 31.295846958586793\n",
            "Train R2 : 0.825282172302819\n",
            "TesT RMSE : 60.54682546546031\n",
            "Test R2 : 0.4416231071937671\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 6 <<<\n",
            "Number of Estimators : 70, Learning Rate : 0.5, Subsample : 0.5\n",
            "Train RMSE : 14.41365956773944\n",
            "Train R2 : 0.9629394104724159\n",
            "TesT RMSE : 76.15266588315947\n",
            "Test R2 : 0.11668642425299047\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 7 <<<\n",
            "Number of Estimators : 70, Learning Rate : 0.5, Subsample : 0.75\n",
            "Train RMSE : 9.378279369184863\n",
            "Train R2 : 0.9843104627635\n",
            "TesT RMSE : 68.41187502478607\n",
            "Test R2 : 0.28713438031330496\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 8 <<<\n",
            "Number of Estimators : 70, Learning Rate : 0.5, Subsample : 1\n",
            "Train RMSE : 8.723526962321582\n",
            "Train R2 : 0.9864247443153982\n",
            "TesT RMSE : 63.61804153879355\n",
            "Test R2 : 0.3835394729122432\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 9 <<<\n",
            "Number of Estimators : 90, Learning Rate : 0.05, Subsample : 0.5\n",
            "Train RMSE : 36.60637301881301\n",
            "Train R2 : 0.7609563539074219\n",
            "TesT RMSE : 57.0608337115253\n",
            "Test R2 : 0.5040693975453703\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 10 <<<\n",
            "Number of Estimators : 90, Learning Rate : 0.05, Subsample : 0.75\n",
            "Train RMSE : 35.879539047039025\n",
            "Train R2 : 0.7703547258498818\n",
            "TesT RMSE : 58.61383379923015\n",
            "Test R2 : 0.47670698272091416\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 11 <<<\n",
            "Number of Estimators : 90, Learning Rate : 0.05, Subsample : 1\n",
            "Train RMSE : 36.762248983428314\n",
            "Train R2 : 0.7589162451549893\n",
            "TesT RMSE : 59.365107719438925\n",
            "Test R2 : 0.46320655615210315\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 12 <<<\n",
            "Number of Estimators : 90, Learning Rate : 0.1, Subsample : 0.5\n",
            "Train RMSE : 28.417601715882235\n",
            "Train R2 : 0.855941579412891\n",
            "TesT RMSE : 60.112401408116845\n",
            "Test R2 : 0.44960708071990496\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 13 <<<\n",
            "Number of Estimators : 90, Learning Rate : 0.1, Subsample : 0.75\n",
            "Train RMSE : 27.43696438934632\n",
            "Train R2 : 0.8657123969929859\n",
            "TesT RMSE : 60.574286519082314\n",
            "Test R2 : 0.4411164878966167\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 14 <<<\n",
            "Number of Estimators : 90, Learning Rate : 0.1, Subsample : 1\n",
            "Train RMSE : 28.292109401020674\n",
            "Train R2 : 0.8572110959664677\n",
            "TesT RMSE : 60.51807329910951\n",
            "Test R2 : 0.4421532995939431\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 15 <<<\n",
            "Number of Estimators : 90, Learning Rate : 0.5, Subsample : 0.5\n",
            "Train RMSE : 11.362464241355617\n",
            "Train R2 : 0.9769692086061839\n",
            "TesT RMSE : 77.40788633249413\n",
            "Test R2 : 0.08732721504320495\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 16 <<<\n",
            "Number of Estimators : 90, Learning Rate : 0.5, Subsample : 0.75\n",
            "Train RMSE : 6.559165261382336\n",
            "Train R2 : 0.9923253081084937\n",
            "TesT RMSE : 68.55541271294422\n",
            "Test R2 : 0.2841398584688335\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 17 <<<\n",
            "Number of Estimators : 90, Learning Rate : 0.5, Subsample : 1\n",
            "Train RMSE : 5.887241037694468\n",
            "Train R2 : 0.9938171681260705\n",
            "TesT RMSE : 63.560065969451834\n",
            "Test R2 : 0.3846625305944077\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 18 <<<\n",
            "Number of Estimators : 120, Learning Rate : 0.05, Subsample : 0.5\n",
            "Train RMSE : 33.521277905112754\n",
            "Train R2 : 0.7995505191632146\n",
            "TesT RMSE : 57.64145377432698\n",
            "Test R2 : 0.493925407834955\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 19 <<<\n",
            "Number of Estimators : 120, Learning Rate : 0.05, Subsample : 0.75\n",
            "Train RMSE : 32.8709667950305\n",
            "Train R2 : 0.8072524981358615\n",
            "TesT RMSE : 58.824766032706684\n",
            "Test R2 : 0.4729338811320921\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 20 <<<\n",
            "Number of Estimators : 120, Learning Rate : 0.05, Subsample : 1\n",
            "Train RMSE : 33.88293759251245\n",
            "Train R2 : 0.7952019041220556\n",
            "TesT RMSE : 59.69688234074558\n",
            "Test R2 : 0.45718981979360096\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 21 <<<\n",
            "Number of Estimators : 120, Learning Rate : 0.1, Subsample : 0.5\n",
            "Train RMSE : 25.091994258665945\n",
            "Train R2 : 0.8876859309493952\n",
            "TesT RMSE : 60.259927595512785\n",
            "Test R2 : 0.44690224766677233\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 22 <<<\n",
            "Number of Estimators : 120, Learning Rate : 0.1, Subsample : 0.75\n",
            "Train RMSE : 23.609724764749057\n",
            "Train R2 : 0.9005635408248256\n",
            "TesT RMSE : 60.853761286269226\n",
            "Test R2 : 0.4359474906772879\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 23 <<<\n",
            "Number of Estimators : 120, Learning Rate : 0.1, Subsample : 1\n",
            "Train RMSE : 24.701846252811613\n",
            "Train R2 : 0.8911514542093426\n",
            "TesT RMSE : 61.38148708916672\n",
            "Test R2 : 0.42612210806792394\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 24 <<<\n",
            "Number of Estimators : 120, Learning Rate : 0.5, Subsample : 0.5\n",
            "Train RMSE : 7.804388758235234\n",
            "Train R2 : 0.9891347032528226\n",
            "TesT RMSE : 77.80368168321802\n",
            "Test R2 : 0.07797015411633346\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 25 <<<\n",
            "Number of Estimators : 120, Learning Rate : 0.5, Subsample : 0.75\n",
            "Train RMSE : 3.654183187662751\n",
            "Train R2 : 0.9976179853235343\n",
            "TesT RMSE : 68.80653083814416\n",
            "Test R2 : 0.2788858693382109\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            ">>> 26 <<<\n",
            "Number of Estimators : 120, Learning Rate : 0.5, Subsample : 1\n",
            "Train RMSE : 3.3420306879144537\n",
            "Train R2 : 0.9980075626719463\n",
            "TesT RMSE : 63.55378619623925\n",
            "Test R2 : 0.38478411602093243\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_zb-hc4LPr3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}